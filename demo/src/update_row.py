#!/usr/bin/env python3
"""
Product Update Module
Ch·ª©c nƒÉng c·∫≠p nh·∫≠t s·∫£n ph·∫©m trong database v·ªõi re-embedding v√† index update
"""

import os
import sys
import pandas as pd
import numpy as np
import faiss
from typing import Dict, List, Optional, Tuple, Any
import json
from datetime import datetime
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'config'))

from simple_config import (
    EMBEDDING_MODEL_NAME, DATA_PATHS, BATCH_SIZE, MAX_LENGTH, get_device
)
from src.embedding import embed_text_with_attention, load_embedding_model
from src.preprocess import create_text_corpus_for_product


class ProductUpdater:
    """Class ƒë·ªÉ c·∫≠p nh·∫≠t th√¥ng tin s·∫£n ph·∫©m trong database"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o ProductUpdater"""
        self.device = get_device()
        self.model = None
        self.tokenizer = None
        self.metadata_df = None
        self.embeddings = None
        self.index = None
        self.load_existing_data()
        
    def load_existing_data(self):
        """Load d·ªØ li·ªáu hi·ªán c√≥"""
        try:
            # Load model
            self.model = SentenceTransformer(EMBEDDING_MODEL_NAME)
            self.tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)
            print("‚úÖ Loaded embedding model")
            
            self._load_data()
                
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            self.metadata_df = None
            self.embeddings = None
            self.index = None
    
    def _load_data(self):
        """Load/reload d·ªØ li·ªáu database"""
        try:
            # Load CSV metadata
            if os.path.exists(DATA_PATHS['metadata']):
                self.metadata_df = pd.read_csv(DATA_PATHS['metadata'])
                print(f"‚úÖ Loaded {len(self.metadata_df)} products from metadata")
            else:
                raise FileNotFoundError("Metadata file not found")
                
            # Load embeddings
            if os.path.exists(DATA_PATHS['embeddings']):
                self.embeddings = np.load(DATA_PATHS['embeddings'])
                print(f"‚úÖ Loaded embeddings: {self.embeddings.shape}")
            else:
                raise FileNotFoundError("Embeddings file not found")
                
            # Load FAISS index
            if os.path.exists(DATA_PATHS['faiss_index']):
                self.index = faiss.read_index(DATA_PATHS['faiss_index'])
                print(f"‚úÖ Loaded FAISS index: {self.index.ntotal} vectors")
            else:
                raise FileNotFoundError("FAISS index not found")
                
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            raise e
    
    def display_products(self, limit: int = 20) -> None:
        """Hi·ªÉn th·ªã danh s√°ch s·∫£n ph·∫©m"""
        print(f"\nüìã Danh s√°ch s·∫£n ph·∫©m (hi·ªÉn th·ªã {min(limit, len(self.metadata_df))} s·∫£n ph·∫©m):")
        print("-" * 100)
        
        for idx, row in self.metadata_df.head(limit).iterrows():
            print(f"ID: {idx:3d} | {row['name'][:50]:<50} | {row['brand'][:20]:<20}")
        
        if len(self.metadata_df) > limit:
            print(f"... v√† {len(self.metadata_df) - limit} s·∫£n ph·∫©m kh√°c")
    
    def search_products(self, query: str) -> List[int]:
        """T√¨m ki·∫øm s·∫£n ph·∫©m theo keyword"""
        if not self.model:
            self.model, self.tokenizer = load_embedding_model()
            
        # Search in name, brand, ingredients
        results = []
        query_lower = query.lower()
        
        for idx, row in self.metadata_df.iterrows():
            search_text = f"{row['name']} {row['brand']} {row.get('ingredients', '')}".lower()
            if query_lower in search_text:
                results.append(idx)
                
        return results
    
    def select_product_to_update(self) -> Optional[int]:
        """Ch·ªçn s·∫£n ph·∫©m ƒë·ªÉ c·∫≠p nh·∫≠t v·ªõi nhi·ªÅu ph∆∞∆°ng th·ª©c"""
        while True:
            print("\nüéØ Ch·ªçn ph∆∞∆°ng th·ª©c t√¨m s·∫£n ph·∫©m c·∫ßn c·∫≠p nh·∫≠t:")
            print("1. Nh·∫≠p ID tr·ª±c ti·∫øp")
            print("2. T√¨m ki·∫øm theo keyword")
            print("3. Xem danh s√°ch s·∫£n ph·∫©m")
            print("0. Quay l·∫°i")
            
            choice = input("\nNh·∫≠p l·ª±a ch·ªçn (0-3): ").strip()
            
            if choice == "0":
                return None
            elif choice == "1":
                return self._select_by_id()
            elif choice == "2":
                return self._select_by_search()
            elif choice == "3":
                return self._select_from_list()
            else:
                print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
    
    def _select_by_id(self) -> Optional[int]:
        """Ch·ªçn s·∫£n ph·∫©m theo ID"""
        try:
            product_id = int(input(f"Nh·∫≠p ID s·∫£n ph·∫©m (0-{len(self.metadata_df)-1}): "))
            if 0 <= product_id < len(self.metadata_df):
                self._display_product_details(product_id)
                if input("X√°c nh·∫≠n c·∫≠p nh·∫≠t s·∫£n ph·∫©m n√†y? (y/n): ").lower() == 'y':
                    return product_id
            else:
                print(f"‚ùå ID kh√¥ng h·ª£p l·ªá! Ph·∫£i t·ª´ 0 ƒë·∫øn {len(self.metadata_df)-1}")
        except ValueError:
            print("‚ùå ID ph·∫£i l√† s·ªë nguy√™n!")
        return None
    
    def _select_by_search(self) -> Optional[int]:
        """Ch·ªçn s·∫£n ph·∫©m qua t√¨m ki·∫øm"""
        query = input("Nh·∫≠p keyword t√¨m ki·∫øm: ").strip()
        if not query:
            return None
            
        results = self.search_products(query)
        if not results:
            print("‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o!")
            return None
            
        print(f"\nüîç T√¨m th·∫•y {len(results)} s·∫£n ph·∫©m:")
        print("-" * 80)
        
        for i, idx in enumerate(results[:10], 1):
            row = self.metadata_df.iloc[idx]
            print(f"{i:2d}. ID:{idx:3d} | {row['name'][:40]:<40} | {row['brand'][:15]}")
            
        try:
            choice = int(input(f"\nCh·ªçn s·∫£n ph·∫©m (1-{min(len(results), 10)}): ")) - 1
            if 0 <= choice < min(len(results), 10):
                product_id = results[choice]
                self._display_product_details(product_id)
                if input("X√°c nh·∫≠n c·∫≠p nh·∫≠t s·∫£n ph·∫©m n√†y? (y/n): ").lower() == 'y':
                    return product_id
        except ValueError:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá!")
        return None
    
    def _select_from_list(self) -> Optional[int]:
        """Ch·ªçn s·∫£n ph·∫©m t·ª´ danh s√°ch"""
        page_size = 20
        total_pages = (len(self.metadata_df) - 1) // page_size + 1
        current_page = 0
        
        while True:
            start_idx = current_page * page_size
            end_idx = min(start_idx + page_size, len(self.metadata_df))
            
            print(f"\nüìã Danh s√°ch s·∫£n ph·∫©m (Trang {current_page + 1}/{total_pages}):")
            print("-" * 80)
            
            for i in range(start_idx, end_idx):
                row = self.metadata_df.iloc[i]
                print(f"{i:3d}. {row['name'][:40]:<40} | {row['brand'][:15]}")
            
            print(f"\n[n]ext | [p]rev | [s]elect | [q]uit")
            choice = input("L·ª±a ch·ªçn: ").strip().lower()
            
            if choice == 'n' and current_page < total_pages - 1:
                current_page += 1
            elif choice == 'p' and current_page > 0:
                current_page -= 1
            elif choice == 's':
                try:
                    product_id = int(input(f"Nh·∫≠p ID s·∫£n ph·∫©m ({start_idx}-{end_idx-1}): "))
                    if start_idx <= product_id < end_idx:
                        self._display_product_details(product_id)
                        if input("X√°c nh·∫≠n c·∫≠p nh·∫≠t s·∫£n ph·∫©m n√†y? (y/n): ").lower() == 'y':
                            return product_id
                    else:
                        print(f"‚ùå ID ph·∫£i t·ª´ {start_idx} ƒë·∫øn {end_idx-1}")
                except ValueError:
                    print("‚ùå ID ph·∫£i l√† s·ªë nguy√™n!")
            elif choice == 'q':
                return None
    
    def _display_product_details(self, product_id: int) -> None:
        """Hi·ªÉn th·ªã chi ti·∫øt s·∫£n ph·∫©m"""
        row = self.metadata_df.iloc[product_id]
        print(f"\nüì¶ Chi ti·∫øt s·∫£n ph·∫©m ID: {product_id}")
        print("-" * 60)
        print(f"T√™n: {row['name']}")
        print(f"Th∆∞∆°ng hi·ªáu: {row['brand']}")
        print(f"Th√†nh ph·∫ßn: {row.get('ingredients', 'N/A')}")
        print(f"Danh m·ª•c: {row.get('categories', 'N/A')}")
        print(f"Nh√† s·∫£n xu·∫•t: {row.get('manufacturer', 'N/A')}")
        print(f"M√£ s·∫£n xu·∫•t: {row.get('manufacturerNumber', 'N/A')}")
    
    def get_updated_product_info(self, current_product: pd.Series) -> Dict[str, Any]:
        """Thu th·∫≠p th√¥ng tin c·∫≠p nh·∫≠t t·ª´ user"""
        print("\n‚úèÔ∏è Nh·∫≠p th√¥ng tin m·ªõi (nh·∫•n Enter ƒë·ªÉ gi·ªØ nguy√™n):")
        print("-" * 50)
        
        updated_info = {}
        
        # C√°c tr∆∞·ªùng b·∫Øt bu·ªôc
        required_fields = ['name', 'brand', 'ingredients']
        for field in required_fields:
            current_value = current_product.get(field, '')
            print(f"Hi·ªán t·∫°i - {field}: {current_value}")
            new_value = input(f"M·ªõi - {field}: ").strip()
            updated_info[field] = new_value if new_value else current_value
        
        # C√°c tr∆∞·ªùng t√πy ch·ªçn
        optional_fields = ['categories', 'manufacturer', 'manufacturerNumber']
        for field in optional_fields:
            current_value = current_product.get(field, '')
            print(f"Hi·ªán t·∫°i - {field}: {current_value}")
            new_value = input(f"M·ªõi - {field}: ").strip()
            updated_info[field] = new_value if new_value else current_value
        
        return updated_info
    
    def _create_embedding(self, product_info: Dict[str, Any]) -> np.ndarray:
        """T·∫°o embedding cho s·∫£n ph·∫©m"""
        if not self.model:
            self.model, self.tokenizer = load_embedding_model()
        
        # T·∫°o text corpus
        text_corpus = create_text_corpus_for_product(
            name=product_info['name'],
            brand=product_info['brand'], 
            ingredients=product_info.get('ingredients', ''),
            categories=product_info.get('categories', ''),
            manufacturer=product_info.get('manufacturer', ''),
            manufacturerNumber=product_info.get('manufacturerNumber', '')
        )
        
        # T·∫°o embedding
        embedding = embed_text_with_attention(
            text_corpus,
            self.model,
            self.tokenizer,
            max_length=MAX_LENGTH,
            device=self.device
        )
        
        # Convert to CPU and numpy before reshape
        embedding_numpy = embedding.detach().cpu().numpy()
        return embedding_numpy.reshape(1, -1)
    
    def update_product(self, product_id: int, updated_info: Dict[str, Any]) -> bool:
        """C·∫≠p nh·∫≠t s·∫£n ph·∫©m trong database"""
        try:
            print(f"\nüîÑ ƒêang c·∫≠p nh·∫≠t s·∫£n ph·∫©m ID: {product_id}...")
            
            # 0. T√¨m index c·ªßa product_id trong DataFrame
            if product_id not in self.metadata_df['id'].values:
                print(f"‚ùå Product ID {product_id} kh√¥ng t·ªìn t·∫°i!")
                return False
            
            # L·∫•y index th·ª±c t·∫ø c·ªßa product_id
            product_index = self.metadata_df[self.metadata_df['id'] == product_id].index[0]
            
            # Debug: Ki·ªÉm tra consistency
            print(f"üîç Debug info:")
            print(f"   Product ID: {product_id}")
            print(f"   Product index in DataFrame: {product_index}")
            print(f"   Metadata shape: {self.metadata_df.shape}")
            print(f"   Embeddings shape: {self.embeddings.shape}")
            print(f"   FAISS index size: {self.index.ntotal}")
            
            # Validation: ƒê·∫£m b·∫£o index kh√¥ng v∆∞·ª£t qu√° bounds
            if product_index >= len(self.embeddings):
                print(f"‚ùå Error: product_index {product_index} >= embeddings size {len(self.embeddings)}")
                print("üîÑ Rebuilding embeddings to match metadata...")
                self._rebuild_all_embeddings()
                # Sau khi rebuild, ki·ªÉm tra l·∫°i
                if product_index >= len(self.embeddings):
                    print(f"‚ùå Still out of bounds after rebuild!")
                    return False
            
            # 1. T·∫°o embedding m·ªõi
            print("üìä T·∫°o embedding m·ªõi...")
            new_embedding = self._create_embedding(updated_info)
            
            # 2. C·∫≠p nh·∫≠t metadata trong DataFrame (s·ª≠ d·ª•ng index, kh√¥ng ph·∫£i ID)
            print("üìù C·∫≠p nh·∫≠t metadata...")
            for field, value in updated_info.items():
                self.metadata_df.at[product_index, field] = value
            
            # C·∫≠p nh·∫≠t text_corpus v·ªõi th√¥ng tin m·ªõi
            new_text_corpus = create_text_corpus_for_product(
                name=updated_info['name'],
                brand=updated_info['brand'], 
                ingredients=updated_info.get('ingredients', ''),
                categories=updated_info.get('categories', ''),
                manufacturer=updated_info.get('manufacturer', ''),
                manufacturerNumber=updated_info.get('manufacturerNumber', '')
            )
            self.metadata_df.at[product_index, 'text_corpus'] = new_text_corpus
            
            # 3. C·∫≠p nh·∫≠t embedding trong array (s·ª≠ d·ª•ng index)
            print("üî¢ C·∫≠p nh·∫≠t embedding...")
            self.embeddings[product_index] = new_embedding.flatten()
            
            # 4. C·∫≠p nh·∫≠t FAISS index (QUICK UPDATE)
            print("üìö C·∫≠p nh·∫≠t FAISS index...")
            
            # Normalize embedding cho cosine similarity
            normalized_embedding = new_embedding.copy()
            faiss.normalize_L2(normalized_embedding)
            
            # Quick update: Ch·ªâ remove v√† add l·∫°i vector n√†y
            try:
                self.index.remove_ids(np.array([product_index], dtype=np.int64))
                self.index.add_with_ids(normalized_embedding, np.array([product_index], dtype=np.int64))
                print(f"‚ö° Quick update vector at index {product_index}")
                
            except Exception as idx_error:
                print(f"‚ö†Ô∏è Quick update failed: {idx_error}")
                print("üîÑ Rebuilding index...")
                self._rebuild_faiss_index()
            
            # 5. L∆∞u d·ªØ li·ªáu
            print("üíæ L∆∞u d·ªØ li·ªáu...")
            self._save_data()
            
            print(f"‚úÖ C·∫≠p nh·∫≠t th√†nh c√¥ng s·∫£n ph·∫©m ID: {product_id}")
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t s·∫£n ph·∫©m: {e}")
            return False
    
    def _rebuild_faiss_index(self):
        """Rebuild to√†n b·ªô FAISS index"""
        embedding_dim = self.embeddings.shape[1]
        
        # T·∫°o IndexIDMap m·ªõi
        base_index = faiss.IndexFlatIP(embedding_dim)
        self.index = faiss.IndexIDMap(base_index)
        
        # Normalize embeddings cho cosine similarity
        normalized_embeddings = self.embeddings.copy()
        faiss.normalize_L2(normalized_embeddings)
        
        # Th√™m t·∫•t c·∫£ embeddings v·ªõi ID
        ids = np.arange(len(self.embeddings), dtype=np.int64)
        self.index.add_with_ids(normalized_embeddings, ids)
        
        print(f"‚úÖ Rebuilt FAISS index v·ªõi {self.index.ntotal} vectors")
    
    def _rebuild_all_embeddings(self):
        """Rebuild to√†n b·ªô embeddings t·ª´ metadata"""
        try:
            print("üîÑ Rebuilding all embeddings from metadata...")
            
            embeddings_list = []
            
            for idx, row in self.metadata_df.iterrows():
                # T·∫°o embedding t·ª´ text_corpus ho·∫∑c t·ª´ c√°c field
                if 'text_corpus' in row and pd.notna(row['text_corpus']):
                    text = row['text_corpus']
                else:
                    # T·∫°o text_corpus t·ª´ c√°c field
                    text = create_text_corpus_for_product(
                        name=row.get('name', ''),
                        brand=row.get('brand', ''),
                        ingredients=row.get('ingredients', ''),
                        categories=row.get('categories', ''),
                        manufacturer=row.get('manufacturer', ''),
                        manufacturerNumber=row.get('manufacturerNumber', '')
                    )
                
                # T·∫°o embedding
                embedding = embed_text_with_attention(
                    text,
                    self.model,
                    self.tokenizer,
                    max_length=MAX_LENGTH,
                    device=self.device
                )
                
                embeddings_list.append(embedding.detach().cpu().numpy())
                
                if (idx + 1) % 50 == 0:
                    print(f"   Processed {idx + 1}/{len(self.metadata_df)} products...")
            
            # Convert to numpy array
            self.embeddings = np.array(embeddings_list)
            
            # Rebuild FAISS index
            self._rebuild_faiss_index()
            
            print(f"‚úÖ Rebuilt all embeddings: {self.embeddings.shape}")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi rebuild embeddings: {e}")
            raise e
    
    def _save_data(self):
        """L∆∞u d·ªØ li·ªáu ra file"""
        # L∆∞u CSV metadata
        self.metadata_df.to_csv(DATA_PATHS['metadata'], index=False)
        
        # L∆∞u embeddings
        np.save(DATA_PATHS['embeddings'], self.embeddings)
        
        # L∆∞u FAISS index
        faiss.write_index(self.index, DATA_PATHS['faiss_index'])
        
        print("üíæ ƒê√£ l∆∞u t·∫•t c·∫£ d·ªØ li·ªáu")
    
    def interactive_update(self):
        """Giao di·ªán t∆∞∆°ng t√°c ƒë·ªÉ c·∫≠p nh·∫≠t s·∫£n ph·∫©m"""
        print("üîß CH·ª®C NƒÇNG C·∫¨P NH·∫¨T S·∫¢N PH·∫®M")
        print("=" * 50)
        
        while True:
            # Ch·ªçn s·∫£n ph·∫©m c·∫ßn c·∫≠p nh·∫≠t
            product_id = self.select_product_to_update()
            if product_id is None:
                break
                
            # L·∫•y th√¥ng tin hi·ªán t·∫°i
            current_product = self.metadata_df.iloc[product_id]
            
            # Thu th·∫≠p th√¥ng tin m·ªõi
            updated_info = self.get_updated_product_info(current_product)
            
            # Hi·ªÉn th·ªã preview
            print("\nüëÄ Preview th√¥ng tin m·ªõi:")
            print("-" * 40)
            for field, value in updated_info.items():
                print(f"{field}: {value}")
            
            # X√°c nh·∫≠n c·∫≠p nh·∫≠t
            if input("\nX√°c nh·∫≠n c·∫≠p nh·∫≠t? (y/n): ").lower() == 'y':
                success = self.update_product(product_id, updated_info)
                if success:
                    print("üéâ C·∫≠p nh·∫≠t th√†nh c√¥ng!")
                else:
                    print("üí• C·∫≠p nh·∫≠t th·∫•t b·∫°i!")
            
            # Ti·∫øp t·ª•c?
            if input("\nC·∫≠p nh·∫≠t s·∫£n ph·∫©m kh√°c? (y/n): ").lower() != 'y':
                break
        
        print("üëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng ch·ª©c nƒÉng c·∫≠p nh·∫≠t!")


def main():
    """Main function"""
    try:
        updater = ProductUpdater()
        updater.interactive_update()
    except KeyboardInterrupt:
        print("\n\nüëã ƒê√£ tho√°t ch∆∞∆°ng tr√¨nh")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    main()
